{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a53d3-7c27-43d8-beb2-8ba0da742a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "#I always do this because I always wanna be able to see all of my columns\n",
    "#and as many rows as I want. But be careful because you could accidentally \n",
    "#ask the code to show you like 2 million rows, crushing your machine's memory.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd9d65-5fbb-4ec8-88ef-99eccbc4df4d",
   "metadata": {},
   "source": [
    "# Make a beat-specific geographic crosswalk\n",
    "It can be extremely helpful to have a single document that tells you a bunch of specifics about a single location. For example, it's super helpful to know which neighborhood and Census tract each area school is in so you can quickly pull Census data related to each school. \n",
    "\n",
    "## Download the data we need\n",
    "If you're following along at NICAR2024, you've already got the Census tracts and blocks for Maryland saved in the data folder of this project. \n",
    "\n",
    "If you're trying to replicate this on your own computer or for your own area, you're going to need to download those datasets.\n",
    "\n",
    "Find the shapes you're after here: https://www2.census.gov/geo/tiger/TIGER2022/. Copy the link to the zip file. In a lot of cases the shapefiles are broken out by state. Familiarize yourself with the state FIPS codes.\n",
    "\n",
    "Here are some confusing filenames and what's in them:\n",
    "- PLACE = cities, towns, etc\n",
    "- SCSD and UNSD = school districts\n",
    "- TABBLOCK20 = Census blocks\n",
    "- BG = Census block group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567f841-bac6-4132-9b28-c030c57de0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you're working from home, run this line\n",
    "#tracts_shp = gpd.read_file('https://www2.census.gov/geo/tiger/TIGER2022/TRACT/tl_2022_24_tract.zip')\n",
    "\n",
    "#If you're in the NICAR class, run this line\n",
    "tracts_shp = gpd.read_file('../data/md-census-tracts/tl_2022_24_tract.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c65d22-6ccd-4f1b-850b-8e6d7ae00519",
   "metadata": {},
   "source": [
    "## Filter just the data you need\n",
    "Did you see how long it took to download those files? That's because they big. If we can get the size down so we're just working with the features we need, all of our analysis will go alot faster.\n",
    "\n",
    "There are two types of filters we can do here:\n",
    "- Attribute table filter: filter by the data behind our shapes\n",
    "- Spatial filter: filter by where the features are are geographically\n",
    "\n",
    "### Attribute filter first\n",
    "Let's look at what data are available to us in the attribute table of the tracts. If you're familiar with the Pandas Python library, this should look super familiar to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e304f-015a-4ae8-9857-d6ce37907143",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_shp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d4f263-da34-4be5-bdfb-99e6c3fd1df8",
   "metadata": {},
   "source": [
    "In fact, geopandas can do pretty much everything regular pandas can do. Let's filter these tracts to just Baltimore County tracts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19e899-afd2-495e-a42f-d22f8905f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmore_tracts = tracts_shp.loc[tracts_shp['COUNTYFP'] == '510']\n",
    "print('All MD tracts:',len(tracts_shp))\n",
    "print('Bmore tracts:',len(bmore_tracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8294f580-c0de-429c-b35b-fd9a765e6141",
   "metadata": {},
   "source": [
    "We can used the built-in `plot` to see these shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b49df8-e491-41f2-a400-86e51b5c94b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmore_tracts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f20e80-92ea-4e80-bad6-ef1ca9d11fc2",
   "metadata": {},
   "source": [
    "If you want a sexier visualization library, checkout [plotly](https://plotly.com/python/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1096ab4e-50d2-4402-84f0-7360eb09f2e8",
   "metadata": {},
   "source": [
    "### Now the spatial filter\n",
    "Geopandas can do most everything regular pandas can do AND MORE! For instance, we can ask geopandas to look at a bunch of Maryland schools and just return the ones that are in those Baltmore tracts we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cea38d-8020-4d67-809a-54d9a031cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_schools = gpd.read_file('../data/md-public-schools/EDGE_GEOCODE_PUBLICSCH_2223_Maryland.shp')\n",
    "bmore_schools = md_schools.sjoin(bmore_tracts, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274ca9f-2128-40aa-81d3-5024f0cdd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(md_schools))\n",
    "print(len(bmore_schools))\n",
    "bmore_schools.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f999bc51-8497-468d-9cd0-ce3f71eea344",
   "metadata": {},
   "source": [
    "As you see, there are still the same number or schools. That's because we haven't technically filtered them. We've just add the `bmore_tracts` data to the `md_schools` shapes. But that ALLOWS us to filter now because a ton of these schools aren't going to have tract info. So we can just filter out the ones without tract info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fe0ea8-07f7-426a-a464-45a7ccaf5ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmore_schools = bmore_schools.loc[~(bmore_schools['TRACTCE'].isna())]\n",
    "print(len(bmore_schools))\n",
    "display(bmore_schools.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052b700c-5959-40c7-8fd6-ca334349bac7",
   "metadata": {},
   "source": [
    "## Drop columns we don't need\n",
    "Holy moly, that's a lot of columns. Let's get rid of some of the duplicated ones and the ones we don't need. And maybe rename some of the columns that that are a bit confusing now that we've got all this info in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f731e8-0bc2-46b9-9ba8-aa3d5d269de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmore_schools.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee20b93-bebc-407d-8d4f-d45aed245572",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['NCESSCH', 'LEAID', 'NAME_left', 'OPSTFIPS', 'STREET', 'CITY', 'STATE',\n",
    "             'ZIP', 'STFIP', 'CNTY', 'NMCNTY', 'LOCALE', 'LAT', 'LON', 'CBSA',\n",
    "             'NMCBSA', 'CBSATYPE', 'CSA', 'NMCSA', 'NECTA', 'NMNECTA', 'CD', 'SLDL',\n",
    "             'SLDU', 'SCHOOLYEAR', 'geometry',\n",
    "             'TRACTCE', 'GEOID']\n",
    "rename_cols = {'GEOID':'TRACT_GEOID'}\n",
    "bmore_schools = bmore_schools[keep_cols].rename(columns=rename_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ea076-2ec0-45f2-b38a-64770ea490e9",
   "metadata": {},
   "source": [
    "## Bring in more data\n",
    "You may ask, why didn't we just add more data in that who section that was about adding data, Allie. GEEZ.\n",
    "\n",
    "It's actually pretty important to drop fields that you don't need between joins to avoid errors like:\n",
    "\n",
    "```\n",
    "ValueError: 'index_left' and 'index_right' cannot be names in the frames being joined\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a28e4cf-8d4c-4449-af62-939d4c7114ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmore_hoods = gpd.read_file('../data/bmore-neighborhoods/Neighborhood.shp')\n",
    "bmore_schools_hoods = bmore_schools.sjoin(bmore_hoods,how='left')\n",
    "\n",
    "display(bmore_schools_hoods.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5c2bbb-03ed-452c-ae0c-99b7a9411fd3",
   "metadata": {},
   "source": [
    "Oh no! The two shapefiles we're trying to sjoin are in different projections! Never fear. It's an easy fix with geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e223388-d67f-42ff-a2de-dea99322f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmore_hoods = gpd.read_file('../data/bmore-neighborhoods/Neighborhood.shp')\n",
    "bmore_hoods = bmore_hoods.to_crs(4269)\n",
    "\n",
    "bmore_schools_hoods = bmore_schools.sjoin(bmore_hoods,how='left')\n",
    "display(bmore_schools_hoods.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d4525a-7485-4ae8-8379-ff54eedf01e8",
   "metadata": {},
   "source": [
    "Look at all of that data! But at this point, there's no indication that those population data stats related to the neighborhoods. Let's try this join one more time, this time using suffixes.\n",
    "\n",
    "Notice we're using just the regular pandas `.add_suffix` here instead of the geopandas sjoin parameter `rsuffix` because rsuffix will only add suffixes if there's column name overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de6a51-8f1d-4a5d-8f0a-2f5781b11176",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmore_hoods = gpd.read_file('../data/bmore-neighborhoods/Neighborhood.shp')\n",
    "bmore_hoods = bmore_hoods.add_suffix('_hoods').set_geometry('geometry_hoods')\n",
    "bmore_hoods = bmore_hoods.to_crs(4269)\n",
    "\n",
    "\n",
    "bmore_schools_hoods = bmore_schools.sjoin(bmore_hoods,how='left')\n",
    "display(bmore_schools_hoods.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf159a1-e48a-4827-b66d-85e6c92ba2ac",
   "metadata": {},
   "source": [
    "## Bring in some tract data\n",
    "At this point, we're pretty much ready to join any Census data that we need onto this bad boi. Since we're fancy AF with our scripted analysis, let's use the Census API.\n",
    "\n",
    "Note: I've been eye-rolled a number of times for not using a python library to interface with the Census API but whatever man. I'm old. I like what I like.\n",
    "\n",
    "Here are the steps to using the Census API:\n",
    "\n",
    "**1. Get an API key [here](https://api.census.gov/data/key_signup.html)**\n",
    "\n",
    "**2. Decide [which survey](https://www.census.gov/data/developers/data-sets.html) you need (decennial, ACS, etc)**\n",
    "\n",
    "**3. Figure out which variables, geographies and years you want to pull data for**\n",
    "Using [the link above](https://www.census.gov/data/developers/data-sets.html), follow the survey dropdowns to find the survey API page. For example, if we wanted the ACS 1-year data we'd go here to learn what geographies and variables are available for it: https://www.census.gov/data/developers/data-sets/acs-1year.html. Here we learn more about the subsets of this dataset (for instance the ACS 1-year has detail tables, subject tables, data tables and comparison tables). Once we know which subset we want, scroll down to find [examples](https://api.census.gov/data/2021/acs/acs1/profile/examples.html), links to variable lists and available geographies for each subset.\n",
    "\n",
    "**4. Construct your URL**\n",
    "I like to put all of the variables I want to pull into a list and then turn that list into a string and feed it into the URL that will fetch the data for us.\n",
    "\n",
    "```\n",
    "FYI, 1-year data are usually only available for larger areas due to sampling size issues. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0cfce-bd2a-4b26-b5ea-9f3636d79b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "MYKEY = '5f5e920f59df757178d859ae70a4cb8297cb739c'\n",
    "\n",
    "#I like to rename my data columns cause I'll get lost otherwise!\n",
    "rename_cols = {'S1903_C03_001E':'med_income_tract',\n",
    "               'S1701_C03_001E':'share_pop_poverty_tract',\n",
    "               'S1701_C03_002E':'share_under18_poverty_tract',\n",
    "              }\n",
    "\n",
    "var_list = ['GEO_ID','NAME']+list(rename_cols.keys())\n",
    "var_str = ','.join(var_list)\n",
    "\n",
    "year = 2022\n",
    "\n",
    "data_url = 'https://api.census.gov/data/'+str(year)+'/acs/acs5/subject?get='+var_str+'&for=tract:*&in=state:24&key='+MYKEY\n",
    "demo_tract_df = pd.read_json(data_url)\n",
    "new_header = demo_tract_df.iloc[0] #grab the first row for the header\n",
    "demo_tract_df = demo_tract_df[1:] #take the data less the header row\n",
    "demo_tract_df.columns = new_header #set the header row as the df header\n",
    "demo_tract_df.rename(columns=rename_cols, inplace=True) #heres where we actually rename\n",
    "\n",
    "print(len(demo_tract_df))\n",
    "display(demo_tract_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4a933-970f-4f4d-b433-956e52cd5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_tract_df.to_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fef2db-4157-4590-8ad1-68018bba22a5",
   "metadata": {},
   "source": [
    "And now all we need to do an attribute join with our existing school data, clean up our columns and export our crosswalk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59bb644-dac1-4c9e-b1f4-4d9e092e58ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmore_schools_hoods_data = bmore_schools_hoods.merge(demo_tract_df,left_on='TRACTCE',right_on='tract')\n",
    "bmore_schools_hoods_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a903da9-4be9-4dcf-ac59-7b16797c6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['NCESSCH', 'LEAID', 'NAME_left', 'STREET', 'CITY', 'STATE','STFIP',\n",
    "             'ZIP', 'CNTY', 'NMCNTY', 'LOCALE', 'LAT', 'LON', 'CBSA',\n",
    "             'NMCBSA', 'CBSATYPE', 'CSA', 'NMCSA', 'NECTA', 'NMNECTA', 'CD', 'SLDL',\n",
    "             'SLDU', 'SCHOOLYEAR', 'geometry', 'TRACTCE', 'TRACT_GEOID',\n",
    "             'Name_hoods', 'Population_hoods','White_hoods', 'Blk_AfAm_hoods', \n",
    "             'AmInd_AkNa_hoods', 'Asian_hoods','NatHaw_Pac_hoods', 'Other_Race_hoods',\n",
    "             'TwoOrMore_hoods','Hisp_Lat_hoods', 'Housing_hoods', 'Occupied_hoods', 'Vacant_hoods',\n",
    "             'med_income_tract','share_pop_poverty_tract', 'share_under18_poverty_tract']\n",
    "rename_cols = {\n",
    "    'NAME_left':'school_name',\n",
    "    'NMCNTY':'county',\n",
    "    'CNTY':'county_fips',\n",
    "    'Name_hoods':'neighborhood',\n",
    "}\n",
    "\n",
    "bmore_schools_hoods_data = bmore_schools_hoods_data[keep_cols].rename(columns=rename_cols)\n",
    "bmore_schools_hoods_data.columns = [x.upper() for x in bmore_schools_hoods_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c21e2a-7a08-40b6-b11b-bffe742df16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmore_schools_hoods_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d00f6-2b7c-42ee-b5b3-1c54304b0309",
   "metadata": {},
   "source": [
    "## In conclusion\n",
    "We could keep adding to this until we've got a thousand columns. There's always more data. An important step to take is talking with your team and figuring out what is most important to them. Since we've scripted this process, what's important can change and we'll be poised to act quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb3ae7-757d-43ae-ab4e-c0e181da8df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
